{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPbpFluRsn50rVrsyDk9h8Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oneoftwo/KAIST_CH453_AI_chemistry/blob/main/assignments/assignment_1/assignment_1_2_problem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0l3z18VhE60d",
        "outputId": "8b88861f-d71e-4ff6-b0af-423e65687ac2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'CH*': No such file or directory\n",
            "rm: cannot remove 'assignment*': No such file or directory\n",
            "rm: cannot remove 'practice*': No such file or directory\n",
            "Cloning into 'KAIST_CH453_AI_chemistry'...\n",
            "remote: Enumerating objects: 25, done.\u001b[K\n",
            "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 25 (delta 4), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (25/25), 1.27 MiB | 3.71 MiB/s, done.\n",
            "Resolving deltas: 100% (4/4), done.\n",
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.10/dist-packages (2024.3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (10.4.0)\n",
            "2024.03.5\n",
            "assignment_1  sample_data\n"
          ]
        }
      ],
      "source": [
        "# DO NOT CHANGE!\n",
        "!rm -r CH*\n",
        "!rm -r assignment*\n",
        "!rm -r practice*\n",
        "!git clone https://github.com/oneoftwo/KAIST_CH453_AI_chemistry/\n",
        "!mv ./KAIST_CH453_AI_chemistry/assignments/assignment_1/ ./\n",
        "!rm -r KAIST_CH453*\n",
        "!pip install rdkit\n",
        "import rdkit\n",
        "print(rdkit.__version__)\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "BIaahCaeGGa2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "from rdkit import RDLogger\n",
        "RDLogger.DisableLog(\"rdApp.*\")\n",
        "\n",
        "\n",
        "class BBBPDataset(Dataset):\n",
        "    def __init__(self, smiles_list, target_list, fp_dim):\n",
        "        assert len(smiles_list) == len(target_list)\n",
        "        self.smiles_list = smiles_list\n",
        "        self.target_list = target_list\n",
        "        self.fp_dim = fp_dim\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.smiles_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        smiles = self.smiles_list[idx]\n",
        "        mol = Chem.MolFromSmiles(smiles)\n",
        "        fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=self.fp_dim)\n",
        "        fp = torch.Tensor(fp)\n",
        "        return fp, self.target_list[idx]\n"
      ],
      "metadata": {
        "id": "1XqTi6-fFTPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, fp_dim, hid_dim, n_layer, dropout):\n",
        "        super().__init__()\n",
        "        # TODO\n",
        "\n",
        "    def forward(self, fp):\n",
        "        # TODO\n"
      ],
      "metadata": {
        "id": "N3O37caYGjaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import functional as F\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "\n",
        "def process(model, data_loader, optimizer=None):\n",
        "    # TODO\n",
        "    return loss, acc, aucroc\n"
      ],
      "metadata": {
        "id": "8ca4-biGSXGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "# arguments\n",
        "fp_dim = 256\n",
        "hid_dim = 256\n",
        "dropout = 0.2\n",
        "n_layer = 2\n",
        "\n",
        "# do not change\n",
        "bs = 32\n",
        "\n",
        "# pre-process dataset\n",
        "train_fn = \"./assignment_1/train.csv\"\n",
        "valid_fn = \"./assignment_1/valid.csv\"\n",
        "test_fn = \"./assignment_1/test.csv\"\n",
        "df = pd.read_csv(train_fn)\n",
        "train_smiles_list, train_target_list = df[\"smiles\"].tolist(), df[\"Class\"].tolist()\n",
        "df = pd.read_csv(valid_fn)\n",
        "valid_smiles_list, valid_target_list = df[\"smiles\"].tolist(), df[\"Class\"].tolist()\n",
        "df = pd.read_csv(test_fn)\n",
        "test_smiles_list, test_target_list = df[\"smiles\"].tolist(), df[\"Class\"].tolist()\n",
        "\n",
        "# construct dataset\n",
        "train_set = BBBPDataset(train_smiles_list, train_target_list, fp_dim=fp_dim)\n",
        "valid_set = BBBPDataset(valid_smiles_list, valid_target_list, fp_dim=fp_dim)\n",
        "test_set = BBBPDataset(test_smiles_list, test_target_list, fp_dim=fp_dim)\n",
        "\n",
        "# make data loader\n",
        "train_loader = DataLoader(train_set, batch_size=bs, shuffle=True, num_workers=2)\n",
        "valid_loader = DataLoader(valid_set, batch_size=bs, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_set, batch_size=bs, shuffle=True, num_workers=2)\n",
        "\n",
        "# initialize model\n",
        "model = Model(fp_dim, hid_dim, n_layer, dropout)\n",
        "model.cuda()\n",
        "print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "print(model, \"\\n\")\n",
        "\n",
        "# train\n",
        "best_aucroc = 0.0\n",
        "for _ in range(3):\n",
        "    model.train()\n",
        "    train_result = process(model, train_loader, optimizer)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        valid_result = process(model, valid_loader)\n",
        "\n",
        "    print(_)\n",
        "    print(train_result)\n",
        "    print(valid_result)\n",
        "    if valid_result[1] > best_aucroc:\n",
        "        best_aucroc = valid_result[1]\n",
        "    print(best_aucroc)\n",
        "\n",
        "test_aucroc = process(model, test_loader)\n",
        "print(\"test\")\n",
        "print(test_aucroc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crSFwKQuKXUI",
        "outputId": "61942869-676a-4ac2-9506-41b6ce15d783"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "66049\n",
            "Model(\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=256, out_features=1, bias=True)\n",
            "  )\n",
            ") \n",
            "\n",
            "0\n",
            "(0.6146574522319593, 0.6972704714640199, 0.7625271912284941)\n",
            "(0.5358940899372101, 0.7615894039735099, 0.8289803220035779)\n",
            "0.7615894039735099\n",
            "1\n",
            "(0.48037265633281906, 0.7907361455748553, 0.8638406099624266)\n",
            "(0.48543896675109866, 0.8211920529801324, 0.8466905187835421)\n",
            "0.8211920529801324\n",
            "2\n",
            "(0.4259307494288997, 0.8064516129032258, 0.8908285908901143)\n",
            "(0.45124844908714296, 0.8211920529801324, 0.8584973166368516)\n",
            "0.8211920529801324\n",
            "test\n",
            "(0.49104424118995665, 0.7631578947368421, 0.8237344093910491)\n"
          ]
        }
      ]
    }
  ]
}