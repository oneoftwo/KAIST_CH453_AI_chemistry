{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyNoa6CyB+8yQMhbok4W3/fR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oneoftwo/KAIST_CH453_AI_chemistry/blob/main/assignments/assignment_2/assignment_2_problem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0l3z18VhE60d",
        "outputId": "79eca9e5-ed7a-412c-ea06-5b1c5d40054f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'CH*': No such file or directory\n",
            "rm: cannot remove 'assignment*': No such file or directory\n",
            "rm: cannot remove 'practice*': No such file or directory\n",
            "Cloning into 'KAIST_CH453_AI_chemistry'...\n",
            "remote: Enumerating objects: 1946, done.\u001b[K\n",
            "remote: Counting objects: 100% (1946/1946), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1939/1939), done.\u001b[K\n",
            "remote: Total 1946 (delta 6), reused 1911 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (1946/1946), 5.40 MiB | 2.88 MiB/s, done.\n",
            "Resolving deltas: 100% (6/6), done.\n",
            "Collecting rdkit\n",
            "  Downloading rdkit-2024.3.5-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (10.4.0)\n",
            "Downloading rdkit-2024.3.5-cp310-cp310-manylinux_2_28_x86_64.whl (33.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.1/33.1 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rdkit\n",
            "Successfully installed rdkit-2024.3.5\n",
            "2024.03.5\n",
            "assignment_2  sample_data\n"
          ]
        }
      ],
      "source": [
        "# DO NOT CHANGE!\n",
        "!rm -r CH*\n",
        "!rm -r assignment*\n",
        "!rm -r practice*\n",
        "!git clone https://github.com/oneoftwo/KAIST_CH453_AI_chemistry/\n",
        "!mv ./KAIST_CH453_AI_chemistry/assignments/assignment_2/ ./\n",
        "!rm -r KAIST_CH453*\n",
        "!pip install rdkit\n",
        "import rdkit\n",
        "print(rdkit.__version__)\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "BIaahCaeGGa2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "from rdkit import RDLogger\n",
        "RDLogger.DisableLog(\"rdApp.*\")\n",
        "\n",
        "\n",
        "class MoleculeImageDataset(Dataset):\n",
        "    def __init__(self, img_list, smiles_list, logp_list, tpsa_list, use_augment=False):\n",
        "        # TPSA and logP are target values\n",
        "        self.img_list = img_list\n",
        "        self.smiles_list = smiles_list\n",
        "        self.logp_list = logp_list\n",
        "        self.tpsa_list = tpsa_list\n",
        "        self.use_augment = use_augment\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.smiles_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # TODO\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "1XqTi6-fFTPP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "19wpoyDfUXst"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class CNNPredictModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # TODO\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO\n",
        "        return x.squeeze(1)\n"
      ],
      "metadata": {
        "id": "N3O37caYGjaq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Process"
      ],
      "metadata": {
        "id": "QiuSm_tPUZsF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import functional as F\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "\n",
        "def process(model, data_loader, optimizer=None):\n",
        "    # you can start with the code below, or you can implement it your own\n",
        "\n",
        "    total_loss, n_data = 0.0, 0\n",
        "    all_p, all_target = [], []\n",
        "    for sample in tqdm(data_loader, disable=False):\n",
        "\n",
        "        # TODO\n",
        "        # update\n",
        "        if optimizer != None:\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    avg_loss = total_loss / n_data\n",
        "\n",
        "    return avg_loss # this will be the average loss per datapoint\n",
        "\n"
      ],
      "metadata": {
        "id": "8ca4-biGSXGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# DO NOT CHANGE\n",
        "def img_to_array_pil(file_name):\n",
        "    # Open the image\n",
        "    img = Image.open(file_name)\n",
        "    img_rgb = img.convert('RGB')\n",
        "    img_array = np.array(img_rgb)\n",
        "    h, w, _ = img_array.shape\n",
        "    img_array = img_array.transpose(2, 0, 1)\n",
        "    return img_array\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "    print(\"Seed has been set to:\", seed)"
      ],
      "metadata": {
        "id": "gINQHkekZIns"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train, Validate, and Test"
      ],
      "metadata": {
        "id": "JMv63d4rUeSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "from torch.utils.data import random_split\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Set the seed\n",
        "set_seed(42)\n",
        "\n",
        "# pre-process dataset\n",
        "data_fn = \"./assignment_2/data.csv\"\n",
        "df = pd.read_csv(data_fn)\n",
        "img_list, tpsa_list, logp_list, smiles_list = [], [], [], []\n",
        "for i in range(1902):\n",
        "    row = df.iloc[i]\n",
        "    img_fn = f\"./assignment_2/images/{i}.png\"\n",
        "    tpsa_list.append(row[\"TPSA\"])\n",
        "    logp_list.append(row[\"LogP\"])\n",
        "    smiles_list.append(row[\"SMILES\"])\n",
        "    img = img_to_array_pil(img_fn) / 255\n",
        "    img_list.append(img)\n",
        "# now you got a list of img, tpsa, logp, and smiles\n",
        "\n",
        "# TODO train / validate and test\n"
      ],
      "metadata": {
        "id": "PTeWRBjeMYJv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8b153b1-f385-42f6-af81-ef8270038a03"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed has been set to: 42\n"
          ]
        }
      ]
    }
  ]
}